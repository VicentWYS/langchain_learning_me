"""
Langchain 1.0 基础教程 - 提示词模板（Prompt Templates）
==============================================

本文件演示如何使用 LangChain 的提示词模板系统
涵盖以下核心概念：
1. PromptTemplate - 简单文本模板
2. ChatPromptTemplate - 聊天消息模板
3. 模板变量和格式化
4. 消息模板的组合
5. 实际应用场景
"""

import os
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.prompts import (
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    AIMessagePromptTemplate,
)


# 加载环境变量
load_dotenv()

QWEN_API_KEY = os.getenv("QWEN_API_KEY")
QWEN_BASE_URL = os.getenv("QWEN_BASE_URL")

if not QWEN_API_KEY or QWEN_API_KEY == "your_qwen_api_key_here":
    raise ValueError(
        "\n请现在 .env 文件中设置有效的 QWEN_API_KEY\n"
        "访问 https://bailian.console.aliyun.com/cn-beijing/?tab=model#/api-key 获取免费秘钥"
    )

if not QWEN_BASE_URL or QWEN_BASE_URL == "your_qwen_base_url_here":
    raise ValueError(
        "\n请现在 .env 文件中设置有效的 QWEN_BASE_URL\n"
        "访问 https://bailian.console.aliyun.com/cn-beijing/?tab=model#/model-market/detail/qwen-plus 获取适配 OpenAI 的 url"
    )


# 初始化模型
model = init_chat_model(
    model="qwen-plus",
    model_provider="openai",
    api_key=QWEN_API_KEY,
    base_url=QWEN_BASE_URL,
    temperature=0.8,
)


# ============================================================================
# 示例 1：为什么需要提示词模板？
# ============================================================================
def example_1_why_templates():
    """
    示例1：对比字符串拼接 vs 模板

    - 问题：字符串拼接容易出错、难维护、不可复用
    - 解决：使用提示词模板
    - 模板优势：
        1. 可复用 - 同一个模板可以用于不同的输入
        2. 可维护 - 模板和数据分离，易于修改
        3. 类型安全 - 自动验证变量
        4. 可测试 - 更容易编写测试用例
    """
    print("\n" + "=" * 40)
    print("示例1：为什么需要提示词模板？")
    print("=" * 40)

    # 不推荐：使用字符串拼接
    print("\n【方式1：字符串拼接（不推荐）】")
    print("-" * 40)

    topic = "Python"
    difficulty = "初学者"

    # 难以维护，容易出错
    prompt_str = (
        f"你是一个{difficulty}级别的编程导师。请用一句简单易懂的语言解释{topic}。"
    )
    print(f"提示词：{prompt_str}")

    response = model.invoke(prompt_str)
    print(f"AI 回复：{response.content[:100]}...\n")

    # 推荐：使用 PromptTemplate
    print("【方式2：使用 PromptTemplate （推荐）】")
    print("-" * 40)

    # 创建可复用的模板
    template = PromptTemplate.from_template(
        "你是一个{difficulty}级别的编程导师。请用一句简单易懂的语言解释{topic}。"
    )

    print(f"模板：{template.template}")
    print(f"变量：{template.input_variables}")

    # 使用模板生成提示词
    prompt = template.format(difficulty=difficulty, topic=topic)
    print(f"生成的提示词：{prompt}")

    response = model.invoke(prompt)
    print(f"AI 回复：{response.content[:100]}...\n")


# ============================================================================
# 示例 2：PromptTemplate 基础用法
# ============================================================================
def example_2_prompt_template_basics():
    """
    示例2：PromptTemplate 的基本用法

    - PromptTemplate 用于简单的文本模板
    - 适合单一提示词的场景
    """
    print("\n" + "=" * 40)
    print("示例2：PromptTemplate 基础用法")
    print("=" * 40)

    # 方法1：使用 from_template （最简单）
    print("\n【方法1：from_template（推荐）】")
    template1 = PromptTemplate.from_template("将以下文本翻译为{language}:\n{text}")

    prompt1 = template1.format(language="英文", text="吃过中午饭了没？")
    print(f"生成的提示词：\n{prompt1}\n")

    response1 = model.invoke(prompt1)
    print(f"AI 回复：{response1.content}\n")

    # 方法2：显式指定变量（更严格）
    print("【方法2：显式指定变量】")
    template2 = PromptTemplate(
        input_variables=["language", "text"],
        template="将以下文本翻译为{language}:\n{text}",
    )

    prompt2 = template2.format(language="英文", text="吃过中午饭了没？")
    print(f"生成的提示词：\n{prompt2}\n")

    response2 = model.invoke(prompt2)
    print(f"AI 回复：{response2.content}\n")

    # 方法3：使用 invoke （直接生成消息）
    print("【方法3：使用 invoke （更方便）】")
    template3 = PromptTemplate.from_template("将以下文本翻译为{language}:\n{text}")

    # invoke 直接返回格式化后的值
    prompt3 = template3.invoke({"language": "英文", "text": "吃过中午饭了没？"})
    print(f"生成的提示词：\n{prompt3.to_string()}\n")

    response3 = model.invoke(prompt3)
    print(f"AI 回复：{response3.content}\n")


# ============================================================================
# 示例 3：ChatPromptTemplate - 聊天消息模板
# ============================================================================
def example_3_chat_prompt_template():
    """
    示例3：ChatPromptTemplate 的基本用法

    - ChatPromptTemplate 用于构建聊天消息
    - 支持 system, user, assistant 多种角色
    """
    print("\n" + "=" * 40)
    print("示例3：ChatPromptTemplate - 聊天消息模板")
    print("=" * 40)

    print("\n【方法1：元组格式（推荐）】")

    chat_template = ChatPromptTemplate.from_messages(
        [("system", "你是一名{role}, 擅长{expertise}。"), ("user", "请帮我{task}")]
    )

    print(f"模板变量：{chat_template.input_variables}")

    # 格式化模板
    messages = chat_template.format_messages(
        role="Python 导师",
        expertise="用简单的方式解释复杂概念",
        task="用一句话介绍python的优点",
    )

    print("\n生成的消息：")
    for msg in messages:
        print(f"{msg.type}: {msg.content}")

    response = model.invoke(messages)
    print(f"\nAI 回复：{response.content[:100]}...")


# ============================================================================
# 示例4：多轮对话模板
# ============================================================================
def example_4_conversation_template():
    """
    示例4：构建多轮对话的模板

    - 包含系统提示词、对话历史和当前问题
    - 模板结构：
        * 1. System: 设定角色和指令
        * 2. User: 第一个问题
        * 3. Assistant: 第一个 AI 回答
        * 4. User: 第二个问题（基于上下文）
    """
    print("\n" + "=" * 40)
    print("示例4：多轮对话模板")
    print("=" * 40)

    # 创建包含多轮对话历史的模板
    template = ChatPromptTemplate.from_messages(
        [
            ("system", "你是一个{role}。{instruction}"),
            ("user", "{question1}"),
            ("assistant", "{answer1}"),
            ("user", "{question2}"),
        ]
    )

    # 填充模板
    messages = template.format_messages(
        role="Python 专家",
        instruction="你的回答要简洁、准确。",
        question1="用一句话介绍列表。",
        answer1="列表是 Python 中的有序可变集合，用方括号 [] 表示。",
        question2="它和元组有什么区别？",  # 基于上下文的问题
    )

    print("生成的完整对话：")
    for i, msg in enumerate(messages, 1):  # 让从1开始输出序号 i
        content_preview = (
            msg.content[:60] + "..." if len(msg.content) > 60 else msg.content
        )
        print(f"{i}. [{msg.type} {content_preview}]")

    response = model.invoke(messages)
    print(f"\nAI 回复：{response.content}\n")


# ============================================================================
# 示例5：使用 MessagePromptTemplate （高级）
# ============================================================================
def example_5_message_templates():
    """
    示例5：使用MssagePromptTemplate 类

    - 提供更细粒度的控制
    - 模板组件：
        * 1. SystemMessagePromptTemplate
        * 2. HumanMessagePromptTemplate
    """
    print("\n" + "=" * 40)
    print("示例 5：MessagePromptTemplate 类（高级用法）")
    print("=" * 40)

    # 分别创建不同类型的消息模板
    system_template = SystemMessagePromptTemplate.from_template(
        "你是一个{profession}，你的特长是{specialty}。"
    )

    human_template = HumanMessagePromptTemplate.from_template(
        "关于{topic}，我想知道{question}。"
    )

    # 组合成 ChatPromptTemplate
    chat_template = ChatPromptTemplate.from_messages([system_template, human_template])

    print("模板组件：")
    print(f"  1. SystemMessagePromptTemplate")
    print(f"  2. HumanMessagePromptTemplate")
    print(f"\n总变量：{chat_template.input_variables}\n")

    # 使用模板
    messages = chat_template.format_messages(
        profession="专业的厨师",
        specialty="用通俗准确的语言讲述做菜的方法",
        topic="宫保鸡丁的制作注意点",
        question="应该如何确保炒鸡丁时不粘锅",
    )

    response = model.invoke(messages)
    print(f"AI 回复：{response.content[:100]}...\n")


# ============================================================================
# 示例6：部分变量（Partial Variables）
# ============================================================================
def example_6_partial_variables():
    """
    示例6：部分变量 - 预填充某些变量

    - 使用场景：
        - 某些变量固定不变
        - 需要创建模板变体
    """
    print("\n" + "=" * 40)
    print("示例 6：部分变量（Partial Variables）")
    print("=" * 40)

    # 创建原始模板
    original_template = ChatPromptTemplate.from_messages(
        [("system", "你是一名{role}，你的目标用户是{audience}。"), ("user", "请{task}")]
    )

    print(f"原始模板变量：{original_template.input_variables}\n")

    # 部分填充：固定 role 和 audience
    partially_filled = original_template.partial(
        role="科技博客作者", audience="软件人员"
    )

    print(f"后面需填充的变量：{partially_filled.input_variables}\n")

    # 现在只需要提供 task
    messages1 = partially_filled.format_messages(task="用一句话介绍langchain")

    response1 = model.invoke(messages1)
    print(f"AI 回复：{response1.content[:100]}...\n")

    # 复用模板，不同的 task
    messages2 = partially_filled.format_messages(task="用一句话介绍智能体的运行特点")
    response2 = model.invoke(messages2)
    print(f"AI 回复：{response2.content[:100]}...\n")


# ============================================================================
# 示例7：与 LCEL 链式调用（预览）
# ============================================================================
def example_7_lcel_chains():
    """
    示例7：模板 + 模型的链式调用

    - LangChain Expression Language (LCEL)
    - 链式调用的优势：
        - 1. 代码更简洁
        - 2. 组件可复用
        - 3. 易于调试和监控
    """
    print("\n" + "=" * 80)
    print("示例 7：LCEL 链式调用（预览）")
    print("=" * 80)

    # 创建模板
    template = ChatPromptTemplate.from_messages(
        [("system", "你是一名{role}。"), ("user", "{input}")]
    )

    # 使用 | 运算符创建链
    chain = template | model

    # 直接调用链
    response = chain.invoke(
        {"role": "技术博客作者", "input": "请用一句话介绍智能体是什么"}
    )
    print(f"AI 回复：{response.content[:100]}...\n")


def main():
    """
    主程序：运行所有示例
    """
    print("\n" + "=" * 80)
    print("Langchain 1.0 基础教程 - 提示词模板")
    print("=" * 80)

    try:
        # example_1_why_templates()
        # example_2_prompt_template_basics()
        # example_3_chat_prompt_template()
        # example_4_conversation_template()
        # example_5_message_templates()
        # example_6_partial_variables()
        example_7_lcel_chains()

        print("=" * 80)
        print("所有示例运行完成！")
        print("=" * 80)

    except KeyboardInterrupt:
        print("\n\n程序被用户中断")

    except Exception as e:
        print(f"\n运行出错：{e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
